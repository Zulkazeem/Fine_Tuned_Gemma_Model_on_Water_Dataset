{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUL5YgBdS9ra",
        "outputId": "8cbbe77d-ed00-4aa1-85fc-1835ce2cc463"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# # TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# # THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# # NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# # ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# # NOTEBOOK.\n",
        "\n",
        "# import os\n",
        "# import sys\n",
        "# from tempfile import NamedTemporaryFile\n",
        "# from urllib.request import urlopen\n",
        "# from urllib.parse import unquote, urlparse\n",
        "# from urllib.error import HTTPError\n",
        "# from zipfile import ZipFile\n",
        "# import tarfile\n",
        "# import shutil\n",
        "\n",
        "# CHUNK_SIZE = 40960\n",
        "# DATA_SOURCE_MAPPING = 'databricks-dolly-15k:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3122881%2F5385487%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240918%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240918T224103Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D21e5e4e9e916dfeaa61afc6e426d5884fd749da6e6a77a9c15ec65ae575d0b791646130975ff0c06e7f2231cf4b38ec65b124f97bb4aed92f65e6941ce7c255d21893962f8f05cb087e3ba6d87269661c09cc26bcc8bf19301386d868f614ae9c6631710cd16f7b839194a7ae4015fb07f27f265bb536156a00efca19d1f8bf972d9d5fe5dcb54be67ad1aeaf55b6375905f6ab0b3383bf810ab808a96241150fba7f2e1e829efb26bda6f3aa5f3438475571c6e554d3c287aae7b2afc3f5259f4257cfdf21c04e996c80a2a1b6a9e5d65f985a31b7ebf4bd37c037e5aaaf022c350eac71df6d1131a9d01a5efb553a8c1d04ee72dc84bb03e8cfd2044c679ca,llm-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5696964%2F9388819%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240918%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240918T224103Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D54f624867dfd61929f5982f7976592b02ad7ee42de8df292586585bfc77bf0bd780f285192698407573a5d6cc1beff6748ed9729d78a29a74856516fbbf16aed4b38c9849df3ff39ca7633fb3f20df9d4df5b1706f094a46d47251f5a3c401b186425e5ab74ff0d52c245f2326166725c95c178fe378a709135fd28c9ceae62010e8588ad3211dc8c48ad365117068d55b84b4753065c7fc47dd57951dce4c5c41110d43815426e3e2a37dc3f13d6ea6d7f361772efcb57465b97b717657411fc352972da781e5817a11aeaf5d336134d9d81df46a934ffeead00e9a17be37fbf3803ac386c0201707c69d06084591495efddfedb2a06fde9432a3d2f92807b8,gemma/keras/gemma_2b_en/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F5171%2F10260%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240918%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240918T224103Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D50f41ca900bab0a8df455ace63931a1a753300ba324bc33f0fcbdea306f33ba55d80d092ead9eac4604983e4b6dcb3e61f08345241a06d41c33d3b67132e76936605bd1f050ed7df5a83a4cb49278cccadf25e7cea6b50093784fc19363aed3000fd7ad59da42cde1e9fcf074a972d14f1c9a2a7c994528c635e1415668af60d2d3a19b2c5a38fa934b0d903c1ffd5e492ddcc1328bafe4b0ffdb8038bc39760a46112ab6cd3cfe05e3eef7329fb3d08667ec0035bd3aadca150d73fc63bb648c01d510b1d6d19ce3031b9f0cf968c8507d9cd9137d9e440fb8e8e286fb3d542b323f34a528b1e6642cbd020a8a68d5cdc9640c6cf75d607ab5ff69fd1089f57,gemma/keras/gemma_2b_en/2:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F5171%2F11371%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240918%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240918T224103Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D11a64c5940fc7c0a21d88fcccb2cae6137a8d5ec4cf1e51d0f8e0867a7893d8bea0b2bb2803b530763e374b6cc81cd038c9bf8b7472acbb55b2e0ccf61e73c585a1bc08ca67b765aa135e7299b677b136db4c7a787630b229898e3c8003d84bb5f6b3a76060b0ef9b86fa8a97b63bc2edd64746b8d018d77708d45dd22d30ea94c78f22a51fbcf46891affe689eb63867b9a2224a7901c0b02fcb6cdde5e5a645af99fd66a90ac880c39bb0a6e7b92ca8be01ee63a2ec44656e6d7b8d162374b107fed8f06e5ba9a038a015ba1baff81816d91405fecef74497710483e3fa96f916e9a6e0be2187d5c040e2164b696791806796176215a202370935279f2f375'\n",
        "\n",
        "# KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "# KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "# KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "# !umount /kaggle/input/ 2> /dev/null\n",
        "# shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "# os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "# os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "# try:\n",
        "#   os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "# except FileExistsError:\n",
        "#   pass\n",
        "# try:\n",
        "#   os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "# except FileExistsError:\n",
        "#   pass\n",
        "\n",
        "# for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "#     directory, download_url_encoded = data_source_mapping.split(':')\n",
        "#     download_url = unquote(download_url_encoded)\n",
        "#     filename = urlparse(download_url).path\n",
        "#     destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "#     try:\n",
        "#         with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "#             total_length = fileres.headers['content-length']\n",
        "#             print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "#             dl = 0\n",
        "#             data = fileres.read(CHUNK_SIZE)\n",
        "#             while len(data) > 0:\n",
        "#                 dl += len(data)\n",
        "#                 tfile.write(data)\n",
        "#                 done = int(50 * dl / int(total_length))\n",
        "#                 sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "#                 sys.stdout.flush()\n",
        "#                 data = fileres.read(CHUNK_SIZE)\n",
        "#             if filename.endswith('.zip'):\n",
        "#               with ZipFile(tfile) as zfile:\n",
        "#                 zfile.extractall(destination_path)\n",
        "#             else:\n",
        "#               with tarfile.open(tfile.name) as tarfile:\n",
        "#                 tarfile.extractall(destination_path)\n",
        "#             print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "#     except HTTPError as e:\n",
        "#         print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "#         continue\n",
        "#     except OSError as e:\n",
        "#         print(f'Failed to load {download_url} to path {destination_path}')\n",
        "#         continue\n",
        "\n",
        "# print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = r\"../dataset/llm_dataset.jsonl\"\n",
        "with open(file_path, \"r\") as file:\n",
        "    data = file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDEExiAk4fLb",
        "papermill": {
          "duration": 0.00928,
          "end_time": "2024-02-21T09:37:33.77871",
          "exception": false,
          "start_time": "2024-02-21T09:37:33.76943",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrtYHQEPS9re"
      },
      "source": [
        "This is a fine-tuned Gemma model, specifically trained on a stormwater and wastewater dataset. The dataset includes synthetic observations generated for analysis.\n",
        "\n",
        "The code for the generated dataset can be found on [GitHub](add the github link to the repo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4enlpwvIu-3",
        "papermill": {
          "duration": 0.008687,
          "end_time": "2024-02-21T09:37:33.906835",
          "exception": false,
          "start_time": "2024-02-21T09:37:33.898148",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Install dependencies\n",
        "\n",
        "Install Keras, KerasNLP, and other dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1eeBtYqJsZPG",
        "papermill": {
          "duration": 29.215629,
          "end_time": "2024-02-21T09:38:03.131031",
          "exception": false,
          "start_time": "2024-02-21T09:37:33.915402",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yomid\\\\OneDrive - Case Western Reserve University\\\\Desktop\\\\KaggleX\\\\My_Gemma_GPT\\\\.venv\\\\Lib\\\\site-packages\\\\tensorflow\\\\include\\\\tensorflow\\\\compiler\\\\xla\\\\mlir_hlo\\\\_virtual_includes\\\\chlo_legalize_to_hlo_inc_gen\\\\chlo_legalize_to_hlo\\\\generated_chlo_legalize_to_hlo.inc'\n",
            "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
            "\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U keras>=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/22/a5/a0b255295406ed54269814bc93723cfd1a0da63fb9aaf99e1364f07923e5/pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata\n",
            "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\yomid\\onedrive - case western reserve university\\desktop\\kagglex\\my_gemma_gpt\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yomid\\onedrive - case western reserve university\\desktop\\kagglex\\my_gemma_gpt\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/11/c3/005fcca25ce078d2cc29fd559379817424e94885510568bc1bc53d7d5846/pytz-2024.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\yomid\\onedrive - case western reserve university\\desktop\\kagglex\\my_gemma_gpt\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
            "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "   ---------------------------------------- 0.0/508.0 kB ? eta -:--:--\n",
            "   ---- ----------------------------------- 61.4/508.0 kB 1.6 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 337.9/508.0 kB 4.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 508.0/508.0 kB 4.5 MB/s eta 0:00:00\n",
            "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Installing collected packages: pytz, tzdata, pandas\n",
            "Successfully installed pandas-2.2.2 pytz-2024.2 tzdata-2024.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ere1NuatS9rf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGLS-l5TxIR4",
        "papermill": {
          "duration": 0.008909,
          "end_time": "2024-02-21T09:38:03.149611",
          "exception": false,
          "start_time": "2024-02-21T09:38:03.140702",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Select a backend\n",
        "\n",
        "Keras is a high-level, multi-framework deep learning API designed for simplicity and ease of use. Using Keras 3, you can run workflows on one of three backends: TensorFlow, JAX, or PyTorch.\n",
        "\n",
        "For this tutorial, configure the backend for JAX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yn5uy8X8sdD0",
        "papermill": {
          "duration": 0.017153,
          "end_time": "2024-02-21T09:38:03.175604",
          "exception": false,
          "start_time": "2024-02-21T09:38:03.158451",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = 'ayomidezulkazeem'\n",
        "os.environ[\"KAGGLE_KEY\"] = '245a313b018fe8355198d9c48413b991'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZs8XXqUKRmi",
        "papermill": {
          "duration": 0.008992,
          "end_time": "2024-02-21T09:38:03.193546",
          "exception": false,
          "start_time": "2024-02-21T09:38:03.184554",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Import packages\n",
        "\n",
        "Import Keras and KerasNLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement distutils (from versions: none)\n",
            "ERROR: No matching distribution found for distutils\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install distutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FYHyPUA9hKTf",
        "papermill": {
          "duration": 13.723138,
          "end_time": "2024-02-21T09:38:16.925885",
          "exception": false,
          "start_time": "2024-02-21T09:38:03.202747",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'distutils'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_nlp\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTypePolicy\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatDTypePolicy\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Function\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\api\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\api\\activations\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\activations\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exponential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\activations\\activations.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\backend\\__init__.py:9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# When using the torch backend,\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# torch needs to be imported first, otherwise it will segfault\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# upon import.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m any_symbolic_tensors\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_utils\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutocastScope\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasVariable\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\dtypes.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m standardize_dtype\n\u001b[0;32m      7\u001b[0m BOOL_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[0;32m      8\u001b[0m INT_TYPES \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint16\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstateless_scope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_stateless_scope\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstateless_scope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_stateless_scope\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_name\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mKerasVariable\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\utils\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio_dataset_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_dataset_from_directory\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_file\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\utils\\audio_dataset_utils.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_utils\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_io \u001b[38;5;28;01mas\u001b[39;00m tfio\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPool\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\tree\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_same_structure\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flatten\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_nested\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\tree\\tree_api.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optree\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optree\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dmtree\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dmtree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\keras\\src\\tree\\optree_impl.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Register backend-specific node classes\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrackable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_structures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListWrapper\n\u001b[0;32m     19\u001b[0m     optree\u001b[38;5;241m.\u001b[39mregister_pytree_node(\n\u001b[0;32m     20\u001b[0m         ListWrapper,\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: (x, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m metadata, children: ListWrapper(\u001b[38;5;28mlist\u001b[39m(children)),\n\u001b[0;32m     23\u001b[0m         namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_nested\u001b[39m(structure):\n",
            "File \u001b[1;32mc:\\Users\\yomid\\OneDrive - Case Western Reserve University\\Desktop\\KaggleX\\My_Gemma_GPT\\.venv\\Lib\\site-packages\\tensorflow\\__init__.py:30\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import keras_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T7xe_jzslv4",
        "papermill": {
          "duration": 0.008653,
          "end_time": "2024-02-21T09:38:16.943901",
          "exception": false,
          "start_time": "2024-02-21T09:38:16.935248",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45UpBDfBgf0I",
        "papermill": {
          "duration": 0.008546,
          "end_time": "2024-02-21T09:38:16.961234",
          "exception": false,
          "start_time": "2024-02-21T09:38:16.952688",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Preprocess the data. This tutorial uses a subset of 1000 training examples to execute the notebook faster. Consider using more training data for higher quality fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "ro9i5lsgS9rh",
        "outputId": "d78bf385-ee80-4ad0-f990-5b5496b8b1de",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"When is the next maintenance due for Primary Clarifier-756587 based on its last service date?\",\n          \"Based on the lifespan of Sludge Thickener, how much longer can Sludge Thickener-487731 be expected to operate?\",\n          \"What maintenance action was performed on the Activated Sludge System-941141 on 1994-11-12?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"On 1777-04-04 10:31:34, technician Michael Bright performed a emergency repair on Primary Clarifier-756587. The action taken was to emergency repair of membrane in membrane bioreactor. Parts used included Chain and sprockets, Bearings, Skimmer arm. The notes state: 'Emergency repair of membrane in Membrane Bioreactor. Checked and confirmed proper filtration.' The equipment status was Operational with a performance metric of 0.82. The standard maintenance interval for Primary Clarifier is 90 days, and its typical lifespan is 30 years. This Primary Clarifier was installed on 1996-02-22.\",\n          \"On 1753-05-24 10:11:01, technician Virginia Sanders performed a emergency repair on Sludge Thickener-487731. The action taken was to performed immediate repairs on a cracked pipe. Parts used included Scrapers, Bearings, Gearboxes. The notes state: 'Performed immediate repairs on a cracked pipe. Water flow restored and checked for further leaks.' The equipment status was Operational with a performance metric of 0.8. The standard maintenance interval for Sludge Thickener is 60 days, and its typical lifespan is 20 years. This Sludge Thickener was installed on 1945-04-22.\",\n          \"On 1994-11-12 12:35:54, technician Amanda Gutierrez performed a emergency repair on Activated Sludge System-941141. The action taken was to replaced damaged motor starter in control panel. Parts used included Motors, Pumps, Sensors. The notes state: 'Damaged motor starter in control panel replaced. System functioning properly.' The equipment status was Operational with a performance metric of 0.85. The standard maintenance interval for Activated Sludge System is 30 days, and its typical lifespan is 20 years. This Activated Sludge System was installed on 1995-04-17.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Based on the last service date of 1777-04-04 and the standard maintenance interval of 90 days for Primary Clarifier, the next maintenance for Primary Clarifier-756587 is due on 1777-07-03.\",\n          \"The Sludge Thickener-487731 was installed on 1945-04-22 and has been in operation for approximately -191.9 years. Given the typical lifespan of 20 years for Sludge Thickener, it can be expected to operate for about 211.9 more years, assuming proper maintenance. However, its performance should be closely monitored as it approaches the end of its expected lifespan.\",\n          \"A emergency repair was performed on Activated Sludge System-941141, where replaced damaged motor starter in control panel.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"closed_qa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a9d59f90-0c8c-4be5-93c0-0ff1b472ab97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>context</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When is the next maintenance due for Lift Stat...</td>\n",
              "      <td>On 1784-01-12 06:33:12, technician Michael Geo...</td>\n",
              "      <td>Based on the last service date of 1784-01-12 a...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Based on the lifespan of Sludge Thickener, how...</td>\n",
              "      <td>On 1753-05-24 10:11:01, technician Virginia Sa...</td>\n",
              "      <td>The Sludge Thickener-487731 was installed on 1...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When is the next maintenance due for Reverse O...</td>\n",
              "      <td>On 1863-10-05 06:15:22, technician Henry Woods...</td>\n",
              "      <td>Based on the last service date of 1863-10-05 a...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What kind of maintenance would be needed for R...</td>\n",
              "      <td>On 1892-11-17 01:47:25, technician Miranda Hay...</td>\n",
              "      <td>Given that the Reverse Osmosis System-50577 is...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What maintenance action was performed on the M...</td>\n",
              "      <td>On 2002-06-03 14:53:52, technician Ashley Mcbr...</td>\n",
              "      <td>A emergency repair was performed on Membrane B...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What maintenance action was performed on the A...</td>\n",
              "      <td>On 1994-11-12 12:35:54, technician Amanda Guti...</td>\n",
              "      <td>A emergency repair was performed on Activated ...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What kind of maintenance would be needed for G...</td>\n",
              "      <td>On 1709-09-29 08:32:03, technician Timothy Cra...</td>\n",
              "      <td>Given that the Grit Chamber-581333 is currentl...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What maintenance action was performed on the M...</td>\n",
              "      <td>On 1998-11-22 13:34:09, technician Kathleen Cl...</td>\n",
              "      <td>A emergency repair was performed on Membrane B...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>When is the next maintenance due for Primary C...</td>\n",
              "      <td>On 1777-04-04 10:31:34, technician Michael Bri...</td>\n",
              "      <td>Based on the last service date of 1777-04-04 a...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>When is the next maintenance due for Sludge Th...</td>\n",
              "      <td>On 1834-12-24 17:39:33, technician Christina R...</td>\n",
              "      <td>Based on the last service date of 1834-12-24 a...</td>\n",
              "      <td>closed_qa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9d59f90-0c8c-4be5-93c0-0ff1b472ab97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9d59f90-0c8c-4be5-93c0-0ff1b472ab97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9d59f90-0c8c-4be5-93c0-0ff1b472ab97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b8737e14-3ae2-4b62-b946-b979527c7c0f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8737e14-3ae2-4b62-b946-b979527c7c0f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b8737e14-3ae2-4b62-b946-b979527c7c0f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4c370a4b-7699-4755-881e-1ae3aec2bd3c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4c370a4b-7699-4755-881e-1ae3aec2bd3c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                         instruction  \\\n",
              "0  When is the next maintenance due for Lift Stat...   \n",
              "1  Based on the lifespan of Sludge Thickener, how...   \n",
              "2  When is the next maintenance due for Reverse O...   \n",
              "3  What kind of maintenance would be needed for R...   \n",
              "4  What maintenance action was performed on the M...   \n",
              "5  What maintenance action was performed on the A...   \n",
              "6  What kind of maintenance would be needed for G...   \n",
              "7  What maintenance action was performed on the M...   \n",
              "8  When is the next maintenance due for Primary C...   \n",
              "9  When is the next maintenance due for Sludge Th...   \n",
              "\n",
              "                                             context  \\\n",
              "0  On 1784-01-12 06:33:12, technician Michael Geo...   \n",
              "1  On 1753-05-24 10:11:01, technician Virginia Sa...   \n",
              "2  On 1863-10-05 06:15:22, technician Henry Woods...   \n",
              "3  On 1892-11-17 01:47:25, technician Miranda Hay...   \n",
              "4  On 2002-06-03 14:53:52, technician Ashley Mcbr...   \n",
              "5  On 1994-11-12 12:35:54, technician Amanda Guti...   \n",
              "6  On 1709-09-29 08:32:03, technician Timothy Cra...   \n",
              "7  On 1998-11-22 13:34:09, technician Kathleen Cl...   \n",
              "8  On 1777-04-04 10:31:34, technician Michael Bri...   \n",
              "9  On 1834-12-24 17:39:33, technician Christina R...   \n",
              "\n",
              "                                            response   category  \n",
              "0  Based on the last service date of 1784-01-12 a...  closed_qa  \n",
              "1  The Sludge Thickener-487731 was installed on 1...  closed_qa  \n",
              "2  Based on the last service date of 1863-10-05 a...  closed_qa  \n",
              "3  Given that the Reverse Osmosis System-50577 is...  closed_qa  \n",
              "4  A emergency repair was performed on Membrane B...  closed_qa  \n",
              "5  A emergency repair was performed on Activated ...  closed_qa  \n",
              "6  Given that the Grit Chamber-581333 is currentl...  closed_qa  \n",
              "7  A emergency repair was performed on Membrane B...  closed_qa  \n",
              "8  Based on the last service date of 1777-04-04 a...  closed_qa  \n",
              "9  Based on the last service date of 1834-12-24 a...  closed_qa  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Examples of the Dataset\n",
        "data_list = []\n",
        "file_path = \"/kaggle/input/llm-dataset/llm_merged_data.jsonl\"\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i < 10:  # Only process the first two lines\n",
        "            data = json.loads(line)\n",
        "            data_list.append(data)\n",
        "        else:\n",
        "            break  # Stop reading after two lines\n",
        "\n",
        "# Convert to DataFrame and display the first two rows\n",
        "df = pd.DataFrame(data_list)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiS-KU9osh_N",
        "outputId": "12ecfcf9-5772-4f79-e5a6-4e78549080e0",
        "papermill": {
          "duration": 0.327569,
          "end_time": "2024-02-21T09:38:17.297818",
          "exception": false,
          "start_time": "2024-02-21T09:38:16.970249",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "When is the next maintenance due for Lift Station-485083 based on its last service date?\n",
            "\n",
            "Response:\n",
            "Based on the last service date of 1784-01-12 and the standard maintenance interval of 60 days for Lift Station, the next maintenance for Lift Station-485083 is due on 1784-03-12.\n",
            "\n",
            "Instruction:\n",
            "When is the next maintenance due for Lift Station-485083 based on its last service date?\n",
            "\n",
            "Response:\n",
            "Based on the last service date of 1784-01-12 and the standard maintenance interval of 60 days for Lift Station, the next maintenance for Lift Station-485083 is due on 1784-03-12.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "data = []\n",
        "with open(\"/kaggle/input/llm-dataset/llm_merged_data.jsonl\") as file:\n",
        "    for i, line in enumerate(file):\n",
        "        if i >= 1000:  # Stop after reading 1000 rows\n",
        "            break\n",
        "        features = json.loads(line)\n",
        "        template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\\n\".format(**features)\n",
        "        data.append(template)\n",
        "\n",
        "# Print the first item in the list for inspection\n",
        "print(data[0])\n",
        "\n",
        "\n",
        "print(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hASLc6HZwk45",
        "outputId": "cadab7d9-c110-430b-f6ca-60e1367d889c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "When is the next maintenance due for Lift Station-485083 based on its last service date?\n",
            "\n",
            "Response:\n",
            "Based on the last service date of 1784-01-12 and the standard maintenance interval of 60 days for Lift Station, the next maintenance for Lift Station-485083 is due on 1784-03-12.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZJj9UTiS9rh",
        "outputId": "bdbadecc-d75e-43c0-b834-ae892ea7e06f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# Check if the list is empty before accessing elements\n",
        "if data:\n",
        "  print(type(data[0]))\n",
        "\n",
        "  # If the data type is not string, convert it\n",
        "  if not isinstance(data[0], str):\n",
        "    # Example: Convert numerical data to string\n",
        "    data = [str(x) for x in data]\n",
        "else:\n",
        "  print(\"The data list is empty.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RCE3fdGhDE5",
        "papermill": {
          "duration": 0.008892,
          "end_time": "2024-02-21T09:38:17.316544",
          "exception": false,
          "start_time": "2024-02-21T09:38:17.307652",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load Model\n",
        "\n",
        "KerasNLP provides implementations of many popular [model architectures](https://keras.io/api/keras_nlp/models/){:.external}. In this tutorial, you'll create a model using `GemmaCausalLM`, an end-to-end Gemma model for causal language modeling. A causal language model predicts the next token based on previous tokens.\n",
        "\n",
        "Create the model using the `from_preset` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "vz5zLEyLstfn",
        "outputId": "3818aea0-f592-491f-8e2f-dbebecb15d6e",
        "papermill": {
          "duration": 53.182225,
          "end_time": "2024-02-21T09:39:10.507854",
          "exception": false,
          "start_time": "2024-02-21T09:38:17.325629",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                                                  </span><span style=\"font-weight: bold\">                                   Config </span>\n",
              "\n",
              " gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                                                    Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                                                    Vocab size: \u001b[38;5;34m256,000\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                  </span><span style=\"font-weight: bold\"> Output Shape              </span><span style=\"font-weight: bold\">         Param # </span><span style=\"font-weight: bold\"> Connected to               </span>\n",
              "\n",
              " padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
              "\n",
              " token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
              "\n",
              " gemma_backbone                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span>  padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)                                                            token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "\n",
              " token_embedding                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span>  gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)                                                                                 \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                             \u001b[38;5;34m0\u001b[0m  -                          \n",
              "\n",
              " token_ids (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                             \u001b[38;5;34m0\u001b[0m  -                          \n",
              "\n",
              " gemma_backbone                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           \u001b[38;5;34m2,506,172,416\u001b[0m  padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              " (\u001b[38;5;33mGemmaBackbone\u001b[0m)                                                            token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "\n",
              " token_embedding                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)           \u001b[38;5;34m524,288,000\u001b[0m  gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mReversibleEmbedding\u001b[0m)                                                                                 \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
        "gemma_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl4lvPy5zA26",
        "papermill": {
          "duration": 0.012623,
          "end_time": "2024-02-21T09:39:10.53129",
          "exception": false,
          "start_time": "2024-02-21T09:39:10.518667",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The `from_preset` method instantiates the model from a preset architecture and weights. In the code above, the string \"gemma_2b_en\" specifies the preset architecture  a Gemma model with 2 billion parameters.\n",
        "\n",
        "NOTE: A Gemma model with 7\n",
        "billion parameters is also available. To run the larger model in Colab, you need access to the premium GPUs available in paid plans. Alternatively, you can perform [distributed tuning on a Gemma 7B model](https://ai.google.dev/gemma/docs/distributed_tuning) on Kaggle or Google Cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_L6A5J-1QgC",
        "papermill": {
          "duration": 0.010947,
          "end_time": "2024-02-21T09:39:10.55264",
          "exception": false,
          "start_time": "2024-02-21T09:39:10.541693",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Inference before fine tuning\n",
        "\n",
        "In this section, you will query the model with various prompts to see how it responds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVLXadptyo34",
        "papermill": {
          "duration": 0.010445,
          "end_time": "2024-02-21T09:39:10.573368",
          "exception": false,
          "start_time": "2024-02-21T09:39:10.562923",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Maintenace Question\n",
        "\n",
        "Query the model for suggestions on what was done last on am equipment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwQz3xxxKciD",
        "outputId": "28ccd743-7771-46bf-fff7-49ba4f3fa910",
        "papermill": {
          "duration": 16.93148,
          "end_time": "2024-02-21T09:39:27.515282",
          "exception": false,
          "start_time": "2024-02-21T09:39:10.583802",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "Response:\n",
            "The latest maintenance report regarding backup power systems is attached.\n",
            "\n",
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "Response:\n",
            "The latest maintenance report regarding backup power systems is attached.\n",
            "\n",
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "Response:\n",
            "The latest maintenance report regarding backup power systems is attached.\n",
            "\n",
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "Response:\n",
            "The latest maintenance report regarding backup power systems is attached.\n",
            "\n",
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "Response:\n",
            "The latest maintenance report regarding backup power systems is attached.\n",
            "\n",
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "Response:\n",
            "The latest maintenance report regarding backup power systems is attached.\n",
            "\n",
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "Response:\n",
            "The latest maintenance report regarding backup power systems is attached.\n",
            "\n",
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "Response:\n",
            "The latest maintenance report regarding backup power systems is attached.\n",
            "\n",
            "Instruction:\n",
            "Can you describe the latest maintenance report regarding backup power systems\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "prompt = template.format(\n",
        "    instruction=\"Can you describe the latest maintenance report regarding backup power systems\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AePQUIs2h-Ks",
        "papermill": {
          "duration": 0.010616,
          "end_time": "2024-02-21T09:39:27.537776",
          "exception": false,
          "start_time": "2024-02-21T09:39:27.52716",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The model just responds with a recommendation to take a trip to Europe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ74Zz_S0iVv",
        "papermill": {
          "duration": 0.010188,
          "end_time": "2024-02-21T09:39:27.558437",
          "exception": false,
          "start_time": "2024-02-21T09:39:27.548249",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### ELI5 Photosynthesis Prompt\n",
        "\n",
        "Prompt the model to explain photosynthesis in terms simple enough for a 5 year old child to understand.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lorJMbsusgoo",
        "outputId": "7c883a61-ebeb-4d35-9726-ba396723fd7b",
        "papermill": {
          "duration": 5.742136,
          "end_time": "2024-02-21T09:39:33.310999",
          "exception": false,
          "start_time": "2024-02-21T09:39:27.568863",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What kind of maintenance would be needed for Reverse Osmosis System-50577 given its current status?\n",
            "\n",
            "Response:\n",
            "The system is in good working condition. It is recommended to clean the system periodically to maintain its performance.\n",
            "\n",
            "Instruction:\n",
            "What is the recommended frequency of cleaning for Reverse Osmosis System-50577?\n",
            "\n",
            "Response:\n",
            "The frequency of cleaning depends on the amount of water used and the quality of the water. It is recommended to clean the system at least once a month.\n",
            "\n",
            "Instruction:\n",
            "What are the benefits of using Reverse Osmosis System-50577?\n",
            "\n",
            "Response:\n",
            "Reverse Osmosis System-50577 is a water purification system that removes impurities and contaminants from water, resulting in clean and safe drinking water. It is a cost-effective and efficient way to provide clean water for homes, businesses, and communities.\n",
            "\n",
            "Instruction:\n",
            "What are the common problems that can occur with Reverse Osmosis System-50577?\n",
            "\n",
            "Response:\n",
            "Some common problems that can occur with Reverse Osmosis System-50577 include:\n",
            "\n",
            "- Water pressure issues: If the water pressure is too low, it can affect the performance of the system\n"
          ]
        }
      ],
      "source": [
        "prompt = template.format(\n",
        "    instruction=\"What kind of maintenance would be needed for Reverse Osmosis System-50577 given its current status?\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBQieduRizZf",
        "papermill": {
          "duration": 0.010874,
          "end_time": "2024-02-21T09:39:33.333088",
          "exception": false,
          "start_time": "2024-02-21T09:39:33.322214",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The responses contains words that might not be easy to understand for a child such as chlorophyll, glucose, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt7Nr6a7tItO",
        "papermill": {
          "duration": 0.01047,
          "end_time": "2024-02-21T09:39:33.354485",
          "exception": false,
          "start_time": "2024-02-21T09:39:33.344015",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## LoRA Fine-tuning\n",
        "\n",
        "To get better responses from the model, fine-tune the model with Low Rank Adaptation (LoRA) using the Databricks Dolly 15k dataset.\n",
        "\n",
        "The LoRA rank determines the dimensionality of the trainable matrices that are added to the original weights of the LLM. It controls the expressiveness and precision of the fine-tuning adjustments.\n",
        "\n",
        "A higher rank means more detailed changes are possible, but also means more trainable parameters. A lower rank means less computational overhead, but potentially less precise adaptation.\n",
        "\n",
        "This tutorial uses a LoRA rank of 4. In practice, begin with a relatively small rank (such as 4, 8, 16). This is computationally efficient for experimentation. Train your model with this rank and evaluate the performance improvement on your task. Gradually increase the rank in subsequent trials and see if that further boosts performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "RCucu6oHz53G",
        "outputId": "63bb510b-e5f9-440b-edb9-f32f5aa9e10f",
        "papermill": {
          "duration": 0.511035,
          "end_time": "2024-02-21T09:39:33.876166",
          "exception": false,
          "start_time": "2024-02-21T09:39:33.365131",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                                                  </span><span style=\"font-weight: bold\">                                   Config </span>\n",
              "\n",
              " gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                                                    Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                                                    Vocab size: \u001b[38;5;34m256,000\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                  </span><span style=\"font-weight: bold\"> Output Shape              </span><span style=\"font-weight: bold\">         Param # </span><span style=\"font-weight: bold\"> Connected to               </span>\n",
              "\n",
              " padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
              "\n",
              " token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
              "\n",
              " gemma_backbone                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span>  padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)                                                            token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            \n",
              "\n",
              " token_embedding                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span>  gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)                                                                                 \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                             \u001b[38;5;34m0\u001b[0m  -                          \n",
              "\n",
              " token_ids (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                             \u001b[38;5;34m0\u001b[0m  -                          \n",
              "\n",
              " gemma_backbone                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           \u001b[38;5;34m2,507,536,384\u001b[0m  padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              " (\u001b[38;5;33mGemmaBackbone\u001b[0m)                                                            token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            \n",
              "\n",
              " token_embedding                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)           \u001b[38;5;34m524,288,000\u001b[0m  gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mReversibleEmbedding\u001b[0m)                                                                                 \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Enable LoRA for the model and set the LoRA rank to 4.\n",
        "gemma_lm.backbone.enable_lora(rank=4)\n",
        "gemma_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQQ47kcdpbZ9",
        "papermill": {
          "duration": 0.011797,
          "end_time": "2024-02-21T09:39:33.903795",
          "exception": false,
          "start_time": "2024-02-21T09:39:33.891998",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Note that enabling LoRA reduces the number of trainable parameters significantly (from 2.5 billion to 1.3 million)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_Peq7TnLtHse",
        "outputId": "51c632c0-425a-4996-ccbe-def4e3cf2edd",
        "papermill": {
          "duration": 753.447217,
          "end_time": "2024-02-21T09:52:07.365329",
          "exception": false,
          "start_time": "2024-02-21T09:39:33.918112",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-19-f299f76b7d48>\", line 16, in <cell line: 16>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras_nlp/src/utils/pipeline_model.py\", line 191, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nOut of memory while trying to allocate 16793993216 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_55400]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f299f76b7d48>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgemma_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_nlp/src/utils/pipeline_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, sample_weight, validation_data, validation_split, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 )\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         return super().fit(\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-19-f299f76b7d48>\", line 16, in <cell line: 16>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras_nlp/src/utils/pipeline_model.py\", line 191, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nOut of memory while trying to allocate 16793993216 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_55400]"
          ]
        }
      ],
      "source": [
        "# Limit the input sequence length to 512 (to control memory usage).\n",
        "gemma_lm.preprocessor.sequence_length = 512\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "gemma_lm.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "gemma_lm.fit(data, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yd-1cNw1dTn",
        "papermill": {
          "duration": 0.092253,
          "end_time": "2024-02-21T09:52:07.553072",
          "exception": false,
          "start_time": "2024-02-21T09:52:07.460819",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Inference after fine-tuning\n",
        "After fine-tuning, responses follow the instruction provided in the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H55JYJ1a1Kos",
        "papermill": {
          "duration": 0.092097,
          "end_time": "2024-02-21T09:52:07.73732",
          "exception": false,
          "start_time": "2024-02-21T09:52:07.645223",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Europe Trip Prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7cDJHy8WfCB",
        "papermill": {
          "duration": 14.645082,
          "end_time": "2024-02-21T09:52:22.473375",
          "exception": false,
          "start_time": "2024-02-21T09:52:07.828293",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "prompt = template.format(\n",
        "    instruction=\"What should I do on a trip to Europe?\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXP6gg2mjs6u",
        "papermill": {
          "duration": 0.104088,
          "end_time": "2024-02-21T09:52:22.681301",
          "exception": false,
          "start_time": "2024-02-21T09:52:22.577213",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The model now recommends places to visit in Europe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7nVd8Mi1Yta",
        "papermill": {
          "duration": 0.093425,
          "end_time": "2024-02-21T09:52:22.874292",
          "exception": false,
          "start_time": "2024-02-21T09:52:22.780867",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### ELI5 Photosynthesis Prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-2sYl2jqwl7",
        "papermill": {
          "duration": 1.343147,
          "end_time": "2024-02-21T09:52:24.310022",
          "exception": false,
          "start_time": "2024-02-21T09:52:22.966875",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "prompt = template.format(\n",
        "    instruction=\"Explain the process of photosynthesis in a way that a child could understand.\",\n",
        "    response=\"\",\n",
        ")\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCmAmqrvkEhc",
        "papermill": {
          "duration": 0.093039,
          "end_time": "2024-02-21T09:52:24.497343",
          "exception": false,
          "start_time": "2024-02-21T09:52:24.404304",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The model now explains photosynthesis in simpler terms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtj1MWG2HBPv",
        "papermill": {
          "duration": 0.094695,
          "end_time": "2024-02-21T09:52:24.685134",
          "exception": false,
          "start_time": "2024-02-21T09:52:24.590439",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Note that for demonstration purposes, this tutorial fine-tunes the model on a small subset of the dataset for just one epoch and with a low LoRA rank value. To get better responses from the fine-tuned model, you can experiment with:\n",
        "\n",
        "1. Increasing the size of the fine-tuning dataset\n",
        "2. Training for more steps (epochs)\n",
        "3. Setting a higher LoRA rank\n",
        "4. Modifying the hyperparameter values such as `learning_rate` and `weight_decay`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSsRdeiof_rJ",
        "papermill": {
          "duration": 0.091976,
          "end_time": "2024-02-21T09:52:24.869733",
          "exception": false,
          "start_time": "2024-02-21T09:52:24.777757",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Summary and next steps\n",
        "\n",
        "This tutorial covered LoRA fine-tuning on a Gemma model using KerasNLP. Check out the following docs next:\n",
        "\n",
        "* Learn how to [generate text with a Gemma model](https://ai.google.dev/gemma/docs/get_started).\n",
        "* Learn how to perform [distributed fine-tuning and inference on a Gemma model](https://ai.google.dev/gemma/docs/distributed_tuning).\n",
        "* Learn how to [use Gemma open models with Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/open-models/use-gemma).\n",
        "* Learn how to [fine-tune Gemma using KerasNLP and deploy to Vertex AI](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_kerasnlp_to_vertexai.ipynb).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 5459162,
          "datasetId": 3122881,
          "sourceId": 5385487,
          "sourceType": "datasetVersion"
        },
        {
          "databundleVersionId": 9590154,
          "datasetId": 5696964,
          "sourceId": 9388819,
          "sourceType": "datasetVersion"
        },
        {
          "databundleVersionId": 7715865,
          "modelInstanceId": 5171,
          "sourceId": 10260,
          "sourceType": "modelInstanceVersion"
        },
        {
          "databundleVersionId": 7771674,
          "modelInstanceId": 5171,
          "sourceId": 11371,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 897.635437,
      "end_time": "2024-02-21T09:52:28.59121",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-21T09:37:30.955773",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
