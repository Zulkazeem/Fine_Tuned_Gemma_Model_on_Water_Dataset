{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2996243-a398-4e7f-86e6-b1fbb3d0b38f",
   "metadata": {},
   "source": [
    "# Building a Gradio Frontend "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27359fd5-fc05-40aa-b636-97dc340aa77e",
   "metadata": {},
   "source": [
    "## Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d2ba96-e517-4126-b09a-a063155f9596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_nlp in /opt/conda/lib/python3.10/site-packages (0.17.0)\n",
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (1.6.17)\n",
      "Requirement already satisfied: gradio in /opt/conda/lib/python3.10/site-packages (5.4.0)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: keras-hub==0.17.0 in /opt/conda/lib/python3.10/site-packages (from keras_nlp) (0.17.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras_nlp) (1.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras_nlp) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras_nlp) (24.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras_nlp) (2024.9.11)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras_nlp) (13.9.2)\n",
      "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras_nlp) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.17.0->keras_nlp) (2.18.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.20)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.115.4)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.4.2 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.26.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.10)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.9.2)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.12)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.7.1)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.1.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.41.2)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.31.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.4.2->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.4.2->gradio) (12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (74.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.17.0->keras_nlp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.17.0->keras_nlp) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.17.0->keras_nlp) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_nlp kaggle gradio tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8bd9ce4-a2b9-4778-9081-9a0f2cf666f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 18:25:11.752855: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-02 18:25:12.091223: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-02 18:25:12.405681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730571912.649290   37282 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730571912.717301   37282 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-02 18:25:13.338070: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras_nlp\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e9356-246f-4b41-a054-7802f14b9980",
   "metadata": {},
   "source": [
    "## Loading the model from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d553e22c-b794-4ce1-8c66-1179467515b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For safety, add this to kaggle or google secrets\n",
    "os.environ['KAGGLE_USERNAME'] = 'ayomidezulkazeem' #username\n",
    "os.environ['KAGGLE_KEY'] = '245a313b018fe8355198d9c48413b991' #kaggle_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9b993f-8fa3-47b2-a100-f3d604a69bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model files: /home/jupyter/.cache/kagglehub/models/ayomidezulkazeem/hydrosense/keras/gemma-hydrosense-instruct-2b/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.model_download(\"ayomidezulkazeem/hydrosense/keras/gemma-hydrosense-instruct-2b\")\n",
    "\n",
    "print(\"Path to model files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3555c5-18f8-4de6-ac9d-bf8525cb1a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: /home/jupyter/.cache/kagglehub/models/ayomidezulkazeem/hydrosense/keras/gemma-hydrosense-instruct-2b/1\n"
     ]
    }
   ],
   "source": [
    "print(\"Model path:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "624658c2-e268-43c1-8007-a3d73859dc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 18:25:20.979637: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-11-02 18:25:21.020925: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2097152000 exceeds 10% of free system memory.\n",
      "2024-11-02 18:25:24.845235: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2097152000 exceeds 10% of free system memory.\n",
      "2024-11-02 18:25:25.250365: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2097152000 exceeds 10% of free system memory.\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "2024-11-02 18:25:44.663163: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2097152000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/jupyter/.cache/kagglehub/models/ayomidezulkazeem/hydrosense/keras/gemma-hydrosense-instruct-2b/1\"\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbc6ff-00b7-4986-bfda-b6ca83734472",
   "metadata": {},
   "source": [
    "## Post-Processing the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b684e998-f39b-44cf-ba37-e292730a512e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_process_output(prompt, generated_text):\n",
    "    # Remove the prompt if it's repeated at the beginning of the answer\n",
    "    answer = generated_text.strip()\n",
    "    if answer.startswith(prompt):\n",
    "        answer = answer[len(prompt):].strip()\n",
    "\n",
    "    # Remove any leading colons or whitespace\n",
    "    answer = answer.lstrip(':')\n",
    "\n",
    "    # Ensure the answer starts with a capital letter\n",
    "    answer = answer.capitalize()\n",
    "\n",
    "    # Ensure the answer ends with a period if it doesn't already\n",
    "    if not answer.endswith('.'):\n",
    "        answer += '.'\n",
    "\n",
    "    return f\"{answer}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6024cf30-930b-4fbd-ba69-dcb26f8351b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730571993.558518   37488 service.cc:148] XLA service 0x7ff0af000980 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730571993.561311   37488 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1730571993.659753   37488 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the last service date of 2023-02-14 and the bi-annual maintenance interval, the next service due for lift station-485083 is 2023-06-12.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"When is the next maintenance due for Lift Station-485083 based on its last service date?\"\n",
    "generated_text = gemma_lm.generate(prompt, max_length=100)\n",
    "\n",
    "# Apply post-processing\n",
    "formatted_output = post_process_output(prompt, generated_text)\n",
    "print(formatted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbb2e1-0028-4837-ad95-73e46a470561",
   "metadata": {},
   "source": [
    "## Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237c776f-947b-4888-b5f9-54e055ccaff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d8e9e3-bc6f-405a-90e9-f76a5306a0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://65548fd86f47e3c37b.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://65548fd86f47e3c37b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "\n",
    "custom_css = \"\"\"\n",
    "@import url('https://fonts.googleapis.com/css2?family=Edu+AU+VIC+WA+NT+Dots:wght@400..700&family=Give+You+Glory&family=Sofia&family=Sunshiney&family=Vujahday+Script&display=swap');\n",
    ".gradio-container, .gradio-container * {\n",
    "     font-family: \"Playfair Display\", serif;\n",
    "  font-optical-sizing: auto;\n",
    "  font-weight: <weight>;\n",
    "  font-style: normal;\n",
    "}\n",
    "\"\"\"\n",
    "js = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') === 'light') {\n",
    "        url.searchParams.set('__theme', 'light');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "previous_sessions = []\n",
    "memory = [{}]\n",
    "\n",
    "\n",
    "\n",
    "def inference(prompt_text):\n",
    "  prompt_text = prompt_text\n",
    "  generated_text = gemma_lm.generate(prompt_text)\n",
    "\n",
    "  #Apply post-processing\n",
    "  formatted_output = post_process_output(prompt_text, generated_text)\n",
    "  print(formatted_output)\n",
    "\n",
    "  #adding a bit of delay\n",
    "  time.sleep(1)\n",
    "  result = formatted_output\n",
    "  sessions = add_session(prompt_text)\n",
    "  return result, sessions\n",
    "\n",
    "\n",
    "def remember(prompt, result):\n",
    "    global memory\n",
    "    # Store the session as a dictionary\n",
    "    session = {'prompt': prompt, 'result': result}\n",
    "    memory.append(session)\n",
    "\n",
    "    # Update previous_sessions for display\n",
    "    session_display = [f\"Q: {s['prompt']} \\nA: {s['result']}\" for s in memory]\n",
    "    \n",
    "    return \"\\n\\n\".join(session_display)  # Return formatted sessions as a string\n",
    "\n",
    "\n",
    "def add_session(prompt_text):\n",
    "    global previous_sessions\n",
    "    session_name = ' '.join(prompt_text.split()[:5])\n",
    "    \n",
    "    if session_name and session_name not in previous_sessions:\n",
    "        previous_sessions.append(session_name)\n",
    "        \n",
    "    return \"\\n\".join(previous_sessions)  # Return only the session logs as a string\n",
    "\n",
    "\n",
    "def clear_sessions():\n",
    "    global previous_sessions\n",
    "    previous_sessions.clear()\n",
    "    return \"\\n\".join(previous_sessions)\n",
    "\n",
    "def clear_fields():\n",
    "    return \"\", \"\"  # Return empty strings to clear the prompt and output fields\n",
    "\n",
    "\n",
    "with gr.Blocks(theme='gradio/soft', css=custom_css) as demo:\n",
    "    gr.Markdown(\"<center><h1>HydroFlow LLM Demo</h1></center>\")\n",
    "    gr.Markdown(\"<center><h3><i><em>Ask me anything on Wastewater or Stormwater!</em></i></h3></center>\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"## Previous Sessions\")\n",
    "            session_list = gr.Textbox(label=\"Sessions\", value=\"\\n\".join(previous_sessions), interactive=False, lines=4, max_lines=20)\n",
    "            add_button = gr.Button(\"New Session\")\n",
    "            clear_session = gr.Button(\"Clear Session\")\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            output = gr.Textbox(label=\"Result\", lines=5, max_lines=20)\n",
    "            prompt = gr.Textbox(label=\"Enter your Prompt here\", max_lines=20)\n",
    "            \n",
    "            with gr.Row():\n",
    "                generate_btn = gr.Button(\"Generate Answer\", variant=\"primary\", size=\"sm\")\n",
    "                reset_btn = gr.Button(\"Clear Content\", variant=\"secondary\", size=\"sm\", elem_id=\"primary\")\n",
    "\n",
    "\n",
    "    generate_btn.click(\n",
    "        fn=inference,\n",
    "        inputs=[prompt],\n",
    "        outputs=[output, session_list],\n",
    "    )\n",
    "\n",
    "    prompt.submit(\n",
    "        fn=inference,\n",
    "        inputs=[prompt],\n",
    "        outputs=[output, session_list],\n",
    "    )\n",
    "\n",
    "    reset_btn.click(\n",
    "        lambda: (\"\", \"\"),\n",
    "        inputs=None,\n",
    "        outputs=[prompt, output]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Button to clear the prompt and output fields\n",
    "    add_button.click(\n",
    "        fn=clear_fields,  # Only call the clear_fields function\n",
    "        inputs=None,      # No inputs needed\n",
    "        outputs=[prompt, output]  # Clear the prompt and output fields\n",
    ")\n",
    "\n",
    "\n",
    "    clear_session.click(\n",
    "        fn=clear_sessions,\n",
    "        inputs=None,\n",
    "        outputs=[session_list]\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2c0eaa-070e-49c7-84f5-fa300c9cd32c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393a76d2-90ba-4967-b80b-a81171b94fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c2848b4883466697032c8196b8badc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "855af255-6a27-48ee-b076-a61ff6360c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'gradio_llm_app' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/spaces/Zul001/gradio_llm_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d70ad3ea-a480-456d-88f9-394b7e8a25af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/gradio_llm_app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd gradio_llm_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2dbfa76-e6ae-43ea-b718-81b071fd0216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"ayomidezulkazeem@gmail.com\"\n",
    "!git config --global user.name \"Zulkazeem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d80a9cf-ca12-4d08-bdee-8185aeef6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add app.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5696bcdb-7699-4c2c-a9d6-a4d7740898fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 2a7b517] Initial commit\n",
      " 1 file changed, 660 insertions(+)\n",
      " create mode 100644 app.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Initial commit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857d84d4-3d18-4dac-92e1-2a015157399d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 4, done.\n",
      "Counting objects: 100% (4/4), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 7.04 KiB | 7.04 MiB/s, done.\n",
      "Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\n",
      "To https://huggingface.co/spaces/Zul001/gradio_llm_app\n",
      "   2de767a..2a7b517  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e57132-7ef7-4fe6-b1b9-a97a0a14aaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface-cli repo create <Hydrosense>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9371ff-619f-42d9-8326-09190fc23d3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bf1208e-e449-4254-b069-209be3aebddf",
   "metadata": {},
   "source": [
    "Gradio_Interface.ipynb hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4143476-376a-4331-af5d-dc92e4e219a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your Keras model\n",
    "model = tf.keras.models.load_model('gemma_lm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4c077-0e0e-4d94-b6c0-cc92033f7c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
